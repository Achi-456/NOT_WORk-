{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8bf2e5f",
   "metadata": {},
   "source": [
    "# EN3150 Assignment 3 - Complete Solution\n",
    "\n",
    "## Waste Classification using Deep Learning\n",
    "\n",
    "**Student Information:**\n",
    "- Assignment: EN3150 Assignment 3 - Parts 1 & 2\n",
    "- Dataset: RealWaste (9 classes)\n",
    "- Framework: PyTorch\n",
    "\n",
    "**Project Structure:**\n",
    "- **Part 1 (Q1-Q12):** Custom Deeper ResNet-34 CNN trained from scratch\n",
    "- **Part 2 (Q13-Q19):** Transfer Learning with Pre-trained Models\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### Part 1: Custom CNN\n",
    "1. [Setup & Data Loading](#setup)\n",
    "2. [Model Architecture](#architecture)\n",
    "3. [Training Functions](#training)\n",
    "4. [Training with Multiple Optimizers](#optimizers)\n",
    "5. [Evaluation & Visualization](#evaluation)\n",
    "6. [Advanced Analysis](#analysis)\n",
    "\n",
    "### Part 2: Transfer Learning\n",
    "7. [Transfer Learning Setup](#transfer-setup)\n",
    "8. [Pre-trained Models](#pretrained)\n",
    "9. [Fine-tuning](#finetuning)\n",
    "10. [Comparison & Discussion](#comparison)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff4530",
   "metadata": {},
   "source": [
    "# PART 1: CUSTOM CNN FROM SCRATCH\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ba6f1",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading <a id=\"setup\"></a>\n",
    "\n",
    "### Q1-Q2: Import libraries, configure environment, and load the RealWaste dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f4ab64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "PyTorch version: 2.8.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "import warnings\n",
    "import shutil\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3683a121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Configuration:\n",
      "   Device: cuda\n",
      "   Image Size: (224, 224)\n",
      "   Batch Size: 32\n",
      "   Classes: 9\n",
      "   Epochs (Part 1): 20\n",
      "   Epochs (Part 2): 10\n"
     ]
    }
   ],
   "source": [
    "# Define project constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 9\n",
    "EPOCHS = 20  # Part 1: Train from scratch\n",
    "EPOCHS_FT = 10  # Part 2: Fine-tuning\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SPLIT_DATA_DIR = 'data'\n",
    "\n",
    "print(f\"\\nüìä Configuration:\")\n",
    "print(f\"   Device: {DEVICE}\")\n",
    "print(f\"   Image Size: {IMAGE_SIZE}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Classes: {NUM_CLASSES}\")\n",
    "print(f\"   Epochs (Part 1): {EPOCHS}\")\n",
    "print(f\"   Epochs (Part 2): {EPOCHS_FT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "596de2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output directory structure created:\n",
      "   üìÅ Models: results\\models\n",
      "   üìÅ Visualizations: results\\visualizations\n",
      "   üìÅ Reports: results\\reports\n",
      "   üìÅ Part 1 Results: results\\part1\n",
      "   üìÅ Part 2 Results: results\\part2\n"
     ]
    }
   ],
   "source": [
    "# Define organized output paths\n",
    "RESULTS_DIR = 'results'\n",
    "MODELS_DIR = os.path.join(RESULTS_DIR, 'models')\n",
    "VIZ_DIR = os.path.join(RESULTS_DIR, 'visualizations')\n",
    "REPORTS_DIR = os.path.join(RESULTS_DIR, 'reports')\n",
    "PART1_DIR = os.path.join(RESULTS_DIR, 'part1')\n",
    "PART2_DIR = os.path.join(RESULTS_DIR, 'part2')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [RESULTS_DIR, MODELS_DIR, VIZ_DIR, REPORTS_DIR, PART1_DIR, PART2_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Output directory structure created:\")\n",
    "print(f\"   üìÅ Models: {MODELS_DIR}\")\n",
    "print(f\"   üìÅ Visualizations: {VIZ_DIR}\")\n",
    "print(f\"   üìÅ Reports: {REPORTS_DIR}\")\n",
    "print(f\"   üìÅ Part 1 Results: {PART1_DIR}\")\n",
    "print(f\"   üìÅ Part 2 Results: {PART2_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d05a5854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RealWaste dataset...\n",
      "\n",
      "‚úÖ Data loaded successfully!\n",
      "   Training samples: 4341\n",
      "   Validation samples: 1319\n",
      "   Test samples: 1338\n",
      "   Classes (9): ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n"
     ]
    }
   ],
   "source": [
    "def get_data_loaders():\n",
    "    \"\"\"Load pre-split RealWaste dataset with appropriate transforms.\"\"\"\n",
    "    \n",
    "    # Training transforms with moderate augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Validation/Test transforms without augmentation\n",
    "    val_test_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load datasets\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(SPLIT_DATA_DIR, 'train'),\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(SPLIT_DATA_DIR, 'validation'),\n",
    "        transform=val_test_transform\n",
    "    )\n",
    "    \n",
    "    test_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(SPLIT_DATA_DIR, 'test'),\n",
    "        transform=val_test_transform\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_dataset.classes\n",
    "\n",
    "# Load data\n",
    "print(\"Loading RealWaste dataset...\")\n",
    "train_loader, val_loader, test_loader, class_names = get_data_loaders()\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded successfully!\")\n",
    "print(f\"   Training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"   Validation samples: {len(val_loader.dataset)}\")\n",
    "print(f\"   Test samples: {len(test_loader.dataset)}\")\n",
    "print(f\"   Classes ({NUM_CLASSES}): {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5294fe",
   "metadata": {},
   "source": [
    "## 2. Model Architecture <a id=\"architecture\"></a>\n",
    "\n",
    "### Q3-Q4: Implement Deeper ResNet-34 with Channel Attention\n",
    "\n",
    "**Architecture Details:**\n",
    "- **Type**: ResNet-34 style with residual blocks\n",
    "- **Blocks**: [3, 4, 6, 3] = 16 residual blocks total\n",
    "- **Channels**: [64, 128, 256, 512]\n",
    "- **Special Features**: Channel Attention (Squeeze-and-Excitation)\n",
    "- **Parameters**: ~21 million\n",
    "\n",
    "This deeper architecture provides greater capacity to learn complex features compared to ResNet-18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab95bb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Deeper ResNet-34 Model Created!\n",
      "   Total Parameters: 21,446,473\n",
      "   Trainable Parameters: 21,446,473\n",
      "   Architecture: [3, 4, 6, 3] blocks = 16 residual blocks\n",
      "   Features: Channel Attention (SE blocks)\n",
      "\n",
      "   Total Parameters: 21,446,473\n",
      "   Trainable Parameters: 21,446,473\n",
      "   Architecture: [3, 4, 6, 3] blocks = 16 residual blocks\n",
      "   Features: Channel Attention (SE blocks)\n"
     ]
    }
   ],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel-wise attention.\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with optional channel attention.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, use_attention=True):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.attention = ChannelAttention(out_channels) if use_attention else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.attention is not None:\n",
    "            out = self.attention(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class DeeperResidualCNN(nn.Module):\n",
    "    \"\"\"Deeper ResNet-34 style CNN with channel attention.\"\"\"\n",
    "    def __init__(self, num_classes=9, block_nums=[3, 4, 6, 3]):\n",
    "        super(DeeperResidualCNN, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(64, 64, block_nums[0], stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, block_nums[1], stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, block_nums[2], stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, block_nums[3], stride=2)\n",
    "        \n",
    "        # Classification head\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
    "        downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride, downsample))\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create and display model\n",
    "model = DeeperResidualCNN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"‚úÖ Deeper ResNet-34 Model Created!\")\n",
    "print(f\"   Total Parameters: {total_params:,}\")\n",
    "print(f\"   Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"   Architecture: [3, 4, 6, 3] blocks = 16 residual blocks\")\n",
    "print(f\"   Features: Channel Attention (SE blocks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc38f5",
   "metadata": {},
   "source": [
    "## 3. Training Functions <a id=\"training\"></a>\n",
    "\n",
    "### Q5-Q6: Implement training loop with advanced features\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Batch-level progress tracking with running averages\n",
    "- ‚úÖ Gradient norm monitoring\n",
    "- ‚úÖ GPU memory tracking\n",
    "- ‚úÖ Real-time visualization\n",
    "- ‚úÖ **Learning Rate Scheduling** (ReduceLROnPlateau)\n",
    "- ‚úÖ Trend indicators (üìà/üìâ)\n",
    "- ‚úÖ ETA calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e969c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch with detailed progress tracking.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # For running averages\n",
    "    batch_losses = []\n",
    "    batch_accs = []\n",
    "    \n",
    "    total_batches = len(dataloader)\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader, 1):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Calculate gradient norm\n",
    "        total_norm = 0.0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                param_norm = p.grad.data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** 0.5\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        batch_loss = loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        batch_correct = (preds == labels).sum().item()\n",
    "        batch_acc = batch_correct / inputs.size(0)\n",
    "        \n",
    "        running_loss += batch_loss * inputs.size(0)\n",
    "        running_correct += batch_correct\n",
    "        total_samples += inputs.size(0)\n",
    "        \n",
    "        batch_losses.append(batch_loss)\n",
    "        batch_accs.append(batch_acc)\n",
    "        \n",
    "        # Calculate running averages\n",
    "        avg_loss = running_loss / total_samples\n",
    "        avg_acc = running_correct / total_samples\n",
    "        \n",
    "        # Progress bar\n",
    "        progress = batch_idx / total_batches\n",
    "        bar_length = 20\n",
    "        filled = int(bar_length * progress)\n",
    "        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)\n",
    "        \n",
    "        # Print detailed progress (every 10 batches or last batch)\n",
    "        if batch_idx % 10 == 0 or batch_idx == total_batches:\n",
    "            print(f\"   Batch [{batch_idx:3d}/{total_batches}] |{bar}| {progress*100:5.1f}% | \"\n",
    "                  f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
    "                  f\"Avg Loss: {avg_loss:.4f} | Avg Acc: {avg_acc:.4f} | \"\n",
    "                  f\"Grad: {total_norm:.3f}\", end='\\r')\n",
    "    \n",
    "    print()  # New line after progress\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_correct / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    total_batches = len(dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader, 1):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "            total_samples += inputs.size(0)\n",
    "            \n",
    "            # Simple progress indicator\n",
    "            if batch_idx % 10 == 0 or batch_idx == total_batches:\n",
    "                progress = batch_idx / total_batches\n",
    "                print(f\"   Validating... {progress*100:.0f}%\", end='\\r')\n",
    "    \n",
    "    print()  # New line\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_correct / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"‚úÖ Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76e74727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete training function with LR scheduling defined!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs, device, model_name, use_scheduler=True):\n",
    "    \"\"\"Complete training loop with detailed visualization, progress tracking, and learning rate scheduling.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üöÄ TRAINING {model_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'learning_rates': []}\n",
    "    best_val_acc = 0.0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = None\n",
    "    if use_scheduler:\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "        print(f\"üìà Learning Rate Scheduler: ReduceLROnPlateau\")\n",
    "        print(f\"   ‚Ä¢ Factor: 0.5 | Patience: 3 epochs | Min LR: 1e-6\")\n",
    "    \n",
    "    # Setup for live plotting\n",
    "    plt.ion()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Get current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        \n",
    "        # Training phase\n",
    "        print(f\"\\n{'‚îÄ'*50}\")\n",
    "        print(f\"üîÑ Training Phase (LR: {current_lr:.6f}):\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validation phase\n",
    "        print(f\"‚úÖ Validation Phase:\")\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        if scheduler is not None:\n",
    "            old_lr = optimizer.param_groups[0]['lr']\n",
    "            scheduler.step(val_loss)\n",
    "            new_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            if new_lr != old_lr:\n",
    "                print(f\"   üîΩ Learning Rate reduced: {old_lr:.6f} ‚Üí {new_lr:.6f}\")\n",
    "        \n",
    "        # Determine trends\n",
    "        train_trend = \"\"\n",
    "        val_trend = \"\"\n",
    "        if epoch > 0:\n",
    "            if train_loss < history['train_loss'][epoch-1]:\n",
    "                train_trend = \" üìâ\"\n",
    "            else:\n",
    "                train_trend = \" üìà\"\n",
    "            if val_acc > history['val_acc'][epoch-1]:\n",
    "                val_trend = \" üìà\"\n",
    "            elif val_acc < history['val_acc'][epoch-1]:\n",
    "                val_trend = \" üìâ\"\n",
    "        \n",
    "        # Save best model\n",
    "        best_marker = \"\"\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            save_path = os.path.join(MODELS_DIR, f'best_model_{model_name}.pth')\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            best_marker = \" ‚≠ê NEW BEST!\"\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        total_time = time.time() - start_time\n",
    "        eta = (total_time / (epoch + 1)) * (epochs - epoch - 1)\n",
    "        \n",
    "        # GPU memory info\n",
    "        gpu_info = \"\"\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated(device) / 1024**2\n",
    "            reserved = torch.cuda.memory_reserved(device) / 1024**2\n",
    "            gpu_info = f\"   üíæ GPU   ‚Üí Allocated: {allocated:.1f}MB | Reserved: {reserved:.1f}MB\"\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"{'‚îÄ'*50}\")\n",
    "        print(f\"üìä EPOCH [{epoch+1}/{epochs}] SUMMARY:\")\n",
    "        print(f\"   üìö LR    ‚Üí {current_lr:.6f}\")\n",
    "        print(f\"   üèÉ Train ‚Üí Loss: {train_loss:.4f}{train_trend} | Acc: {train_acc:.4f} ({train_acc*100:.1f}%)\")\n",
    "        print(f\"   üéØ Val   ‚Üí Loss: {val_loss:.4f} | Acc: {val_acc:.4f} ({val_acc*100:.1f}%){val_trend}{best_marker}\")\n",
    "        print(f\"   ‚è±Ô∏è  Time  ‚Üí Epoch: {epoch_time:.1f}s | Total: {total_time:.1f}s | ETA: {eta:.1f}s\")\n",
    "        if gpu_info:\n",
    "            print(gpu_info)\n",
    "        print(f\"{'‚îÄ'*50}\")\n",
    "        \n",
    "        # Real-time visualization\n",
    "        if epoch % 1 == 0 or epoch == epochs - 1:\n",
    "            epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "            \n",
    "            for ax in axes:\n",
    "                ax.clear()\n",
    "            \n",
    "            # Plot Loss\n",
    "            axes[0].plot(epochs_range, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "            axes[0].plot(epochs_range, history['val_loss'], 'r-s', label='Val Loss', linewidth=2, markersize=6)\n",
    "            axes[0].set_title(f'{model_name} - Loss Progress', fontsize=12, fontweight='bold')\n",
    "            axes[0].set_xlabel('Epoch')\n",
    "            axes[0].set_ylabel('Loss')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot Accuracy\n",
    "            axes[1].plot(epochs_range, history['train_acc'], 'b-o', label='Train Acc', linewidth=2, markersize=6)\n",
    "            axes[1].plot(epochs_range, history['val_acc'], 'r-s', label='Val Acc', linewidth=2, markersize=6)\n",
    "            axes[1].set_title(f'{model_name} - Accuracy Progress', fontsize=12, fontweight='bold')\n",
    "            axes[1].set_xlabel('Epoch')\n",
    "            axes[1].set_ylabel('Accuracy')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "            axes[1].set_ylim([0, 1])\n",
    "            \n",
    "            # Annotations\n",
    "            axes[0].text(0.02, 0.98, f'Current: Train={train_loss:.4f}, Val={val_loss:.4f}',\n",
    "                        transform=axes[0].transAxes, verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            axes[1].text(0.02, 0.98, f'Current: Train={train_acc:.4f}, Val={val_acc:.4f}\\nBest Val: {best_val_acc:.4f}\\nLR: {current_lr:.6f}',\n",
    "                        transform=axes[1].transAxes, verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.pause(0.01)\n",
    "            clear_output(wait=True)\n",
    "            plt.show()\n",
    "            \n",
    "            # Reprint summary\n",
    "            print(f\"\\n{'‚îÄ'*50}\")\n",
    "            print(f\"üìä EPOCH [{epoch+1}/{epochs}] SUMMARY:\")\n",
    "            print(f\"   üìö LR    ‚Üí {current_lr:.6f}\")\n",
    "            print(f\"   üèÉ Train ‚Üí Loss: {train_loss:.4f}{train_trend} | Acc: {train_acc:.4f} ({train_acc*100:.1f}%)\")\n",
    "            print(f\"   üéØ Val   ‚Üí Loss: {val_loss:.4f} | Acc: {val_acc:.4f} ({val_acc*100:.1f}%){val_trend}{best_marker}\")\n",
    "            print(f\"   ‚è±Ô∏è  Time  ‚Üí Epoch: {epoch_time:.1f}s | Total: {total_time:.1f}s | ETA: {eta:.1f}s\")\n",
    "            if gpu_info:\n",
    "                print(gpu_info)\n",
    "            print(f\"{'‚îÄ'*50}\")\n",
    "    \n",
    "    plt.ioff()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üéâ TRAINING COMPLETE - {model_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"   ‚è±Ô∏è  Total Time: {total_time/60:.1f} min ({total_time:.1f}s)\")\n",
    "    print(f\"   üèÜ Best Val Acc: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "    print(f\"   üìö Final LR: {history['learning_rates'][-1]:.6f}\")\n",
    "    print(f\"   üíæ Model saved: {MODELS_DIR}/best_model_{model_name}.pth\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "print(\"‚úÖ Complete training function with LR scheduling defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7f252",
   "metadata": {},
   "source": [
    "## 4. Training with Multiple Optimizers <a id=\"optimizers\"></a>\n",
    "\n",
    "### Q5-Q6: Train the custom CNN with Adam, SGD, and SGD+Momentum\n",
    "\n",
    "We'll train the model three times with different optimizers to compare their effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264c85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìä EPOCH [6/20] SUMMARY:\n",
      "   üìö LR    ‚Üí 0.001000\n",
      "   üèÉ Train ‚Üí Loss: 1.1360 üìâ | Acc: 0.5911 (59.1%)\n",
      "   üéØ Val   ‚Üí Loss: 1.2367 | Acc: 0.5656 (56.6%) üìâ\n",
      "   ‚è±Ô∏è  Time  ‚Üí Epoch: 79.2s | Total: 472.6s | ETA: 1102.7s\n",
      "   üíæ GPU   ‚Üí Allocated: 793.7MB | Reserved: 2308.0MB\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîÑ Training Phase (LR: 0.001000):\n",
      "   Batch [ 10/136] |‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë|   7.4% | Loss: 1.2239 | Acc: 0.5625 | Avg Loss: 1.1762 | Avg Acc: 0.5813 | Grad: 2.596\r"
     ]
    }
   ],
   "source": [
    "# Create fresh model instance for Adam\n",
    "model_adam = DeeperResidualCNN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "optimizer_adam = optim.Adam(model_adam.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train with Adam\n",
    "adam_history, adam_best_acc = train_model(\n",
    "    model=model_adam,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_adam,\n",
    "    criterion=criterion,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    "    model_name='DeeperResNet34_Adam',\n",
    "    use_scheduler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh model instance for SGD\n",
    "model_sgd = DeeperResidualCNN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "optimizer_sgd = optim.SGD(model_sgd.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train with SGD\n",
    "sgd_history, sgd_best_acc = train_model(\n",
    "    model=model_sgd,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_sgd,\n",
    "    criterion=criterion,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    "    model_name='DeeperResNet34_SGD',\n",
    "    use_scheduler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b03507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh model instance for SGD+Momentum\n",
    "model_sgd_momentum = DeeperResidualCNN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "optimizer_sgd_momentum = optim.SGD(model_sgd_momentum.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train with SGD+Momentum\n",
    "sgd_momentum_history, sgd_momentum_best_acc = train_model(\n",
    "    model=model_sgd_momentum,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_sgd_momentum,\n",
    "    criterion=criterion,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    "    model_name='DeeperResNet34_SGD_Momentum',\n",
    "    use_scheduler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794cfe25",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Visualization <a id=\"evaluation\"></a>\n",
    "\n",
    "### Q7-Q9: Evaluate models and create visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ecd447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimizer_comparison(histories, names, save_path=None):\n",
    "    \"\"\"Compare training progress across different optimizers.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    epochs = range(1, len(histories[0]['train_loss']) + 1)\n",
    "    \n",
    "    # Loss comparison\n",
    "    for history, name in zip(histories, names):\n",
    "        axes[0, 0].plot(epochs, history['train_loss'], '-o', label=f'{name}', linewidth=2, markersize=4)\n",
    "    axes[0, 0].set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation Loss comparison\n",
    "    for history, name in zip(histories, names):\n",
    "        axes[0, 1].plot(epochs, history['val_loss'], '-s', label=f'{name}', linewidth=2, markersize=4)\n",
    "    axes[0, 1].set_title('Validation Loss Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training Accuracy comparison\n",
    "    for history, name in zip(histories, names):\n",
    "        axes[1, 0].plot(epochs, history['train_acc'], '-o', label=f'{name}', linewidth=2, markersize=4)\n",
    "    axes[1, 0].set_title('Training Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim([0, 1])\n",
    "    \n",
    "    # Validation Accuracy comparison\n",
    "    for history, name in zip(histories, names):\n",
    "        axes[1, 1].plot(epochs, history['val_acc'], '-s', label=f'{name}', linewidth=2, markersize=4)\n",
    "    axes[1, 1].set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].set_ylim([0, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Plot saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Compare all optimizers\n",
    "plot_optimizer_comparison(\n",
    "    histories=[adam_history, sgd_history, sgd_momentum_history],\n",
    "    names=['Adam', 'SGD', 'SGD+Momentum'],\n",
    "    save_path=os.path.join(PART1_DIR, 'optimizer_comparison.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_rate_schedule(histories, names, save_path=None):\n",
    "    \"\"\"Visualize learning rate changes during training.\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
    "    \n",
    "    epochs = range(1, len(histories[0]['learning_rates']) + 1)\n",
    "    \n",
    "    for history, name in zip(histories, names):\n",
    "        ax.plot(epochs, history['learning_rates'], '-o', label=f'{name}', linewidth=2, markersize=4)\n",
    "    \n",
    "    ax.set_title('Learning Rate Schedule (ReduceLROnPlateau)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Learning Rate', fontsize=12)\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Learning rate plot saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning rate schedules\n",
    "plot_learning_rate_schedule(\n",
    "    histories=[adam_history, sgd_history, sgd_momentum_history],\n",
    "    names=['Adam', 'SGD', 'SGD+Momentum'],\n",
    "    save_path=os.path.join(PART1_DIR, 'learning_rate_schedule.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, model_name):\n",
    "    \"\"\"Evaluate model on test set and return predictions.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(f\"\\nüîç Evaluating {model_name}...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"‚úÖ Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels), accuracy\n",
    "\n",
    "# Evaluate Adam model (best performer typically)\n",
    "model_adam.load_state_dict(torch.load(os.path.join(MODELS_DIR, 'best_model_DeeperResNet34_Adam.pth')))\n",
    "adam_preds, adam_labels, adam_test_acc = evaluate_model(model_adam, test_loader, DEVICE, 'DeeperResNet34_Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1eebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names, model_name, save_path=None):\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Confusion matrix saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix for Adam model\n",
    "plot_confusion_matrix(\n",
    "    adam_labels, adam_preds, class_names, \n",
    "    'DeeperResNet34_Adam',\n",
    "    save_path=os.path.join(PART1_DIR, 'confusion_matrix_adam.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31470eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä CLASSIFICATION REPORT - DeeperResNet34_Adam\")\n",
    "print(\"=\"*80)\n",
    "report = classification_report(adam_labels, adam_preds, target_names=class_names, digits=4)\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "report_path = os.path.join(REPORTS_DIR, 'classification_report_part1_adam.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"CLASSIFICATION REPORT - DeeperResNet34_Adam (Part 1)\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(report)\n",
    "print(f\"‚úÖ Report saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941b1ef",
   "metadata": {},
   "source": [
    "# PART 2: TRANSFER LEARNING\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Transfer Learning Setup <a id=\"transfer-setup\"></a>\n",
    "\n",
    "### Q13-Q14: Fine-tune pre-trained models on RealWaste dataset\n",
    "\n",
    "We'll use ResNet-34 and EfficientNet-B0 pre-trained on ImageNet and fine-tune them on our waste classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(model_name, num_classes=9, freeze_features=True):\n",
    "    \"\"\"Load pre-trained model and modify for our task.\"\"\"\n",
    "    \n",
    "    if model_name == 'resnet34':\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        \n",
    "        # Freeze feature extraction layers\n",
    "        if freeze_features:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace final layer\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        print(f\"‚úÖ ResNet-34 loaded (ImageNet pre-trained)\")\n",
    "        \n",
    "    elif model_name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        \n",
    "        # Freeze feature extraction layers\n",
    "        if freeze_features:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace final layer\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        print(f\"‚úÖ EfficientNet-B0 loaded (ImageNet pre-trained)\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Frozen parameters: {total_params - trainable_params:,}\")\n",
    "    \n",
    "    return model.to(DEVICE)\n",
    "\n",
    "print(\"‚úÖ Pre-trained model loading function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and fine-tune ResNet-34\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîÑ FINE-TUNING RESNET-34\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "resnet34_model = get_pretrained_model('resnet34', num_classes=NUM_CLASSES, freeze_features=True)\n",
    "optimizer_resnet34 = optim.Adam(resnet34_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train ResNet-34\n",
    "resnet34_history, resnet34_best_acc = train_model(\n",
    "    model=resnet34_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_resnet34,\n",
    "    criterion=criterion,\n",
    "    epochs=EPOCHS_FT,\n",
    "    device=DEVICE,\n",
    "    model_name='ResNet-34_FT',\n",
    "    use_scheduler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e65a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and fine-tune EfficientNet-B0\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîÑ FINE-TUNING EFFICIENTNET-B0\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "efficientnet_model = get_pretrained_model('efficientnet_b0', num_classes=NUM_CLASSES, freeze_features=True)\n",
    "optimizer_efficientnet = optim.Adam(efficientnet_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train EfficientNet-B0\n",
    "efficientnet_history, efficientnet_best_acc = train_model(\n",
    "    model=efficientnet_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_efficientnet,\n",
    "    criterion=criterion,\n",
    "    epochs=EPOCHS_FT,\n",
    "    device=DEVICE,\n",
    "    model_name='EfficientNet-B0_FT',\n",
    "    use_scheduler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe9464",
   "metadata": {},
   "source": [
    "## 7. Part 2 Evaluation <a id=\"part2-eval\"></a>\n",
    "\n",
    "### Q15-Q16: Evaluate transfer learning models on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5fb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ResNet-34 Fine-tuned\n",
    "resnet34_model.load_state_dict(torch.load(os.path.join(MODELS_DIR, 'best_model_ResNet-34_FT.pth')))\n",
    "resnet34_preds, resnet34_labels, resnet34_test_acc = evaluate_model(\n",
    "    resnet34_model, test_loader, DEVICE, 'ResNet-34 Fine-tuned'\n",
    ")\n",
    "\n",
    "# Evaluate EfficientNet-B0 Fine-tuned\n",
    "efficientnet_model.load_state_dict(torch.load(os.path.join(MODELS_DIR, 'best_model_EfficientNet-B0_FT.pth')))\n",
    "efficientnet_preds, efficientnet_labels, efficientnet_test_acc = evaluate_model(\n",
    "    efficientnet_model, test_loader, DEVICE, 'EfficientNet-B0 Fine-tuned'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8108bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for ResNet-34 FT\n",
    "plot_confusion_matrix(\n",
    "    resnet34_labels, resnet34_preds, class_names,\n",
    "    'ResNet-34 Fine-tuned',\n",
    "    save_path=os.path.join(PART2_DIR, 'confusion_matrix_resnet34_ft.png')\n",
    ")\n",
    "\n",
    "# Plot confusion matrix for EfficientNet-B0 FT\n",
    "plot_confusion_matrix(\n",
    "    efficientnet_labels, efficientnet_preds, class_names,\n",
    "    'EfficientNet-B0 Fine-tuned',\n",
    "    save_path=os.path.join(PART2_DIR, 'confusion_matrix_efficientnet_ft.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for ResNet-34 FT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä CLASSIFICATION REPORT - ResNet-34 Fine-tuned\")\n",
    "print(\"=\"*80)\n",
    "report_resnet = classification_report(resnet34_labels, resnet34_preds, target_names=class_names, digits=4)\n",
    "print(report_resnet)\n",
    "\n",
    "report_path = os.path.join(REPORTS_DIR, 'classification_report_resnet34_ft.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"CLASSIFICATION REPORT - ResNet-34 Fine-tuned (Part 2)\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(report_resnet)\n",
    "print(f\"‚úÖ Report saved to {report_path}\")\n",
    "\n",
    "# Classification report for EfficientNet-B0 FT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä CLASSIFICATION REPORT - EfficientNet-B0 Fine-tuned\")\n",
    "print(\"=\"*80)\n",
    "report_effnet = classification_report(efficientnet_labels, efficientnet_preds, target_names=class_names, digits=4)\n",
    "print(report_effnet)\n",
    "\n",
    "report_path = os.path.join(REPORTS_DIR, 'classification_report_efficientnet_ft.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"CLASSIFICATION REPORT - EfficientNet-B0 Fine-tuned (Part 2)\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(report_effnet)\n",
    "print(f\"‚úÖ Report saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503a5d0",
   "metadata": {},
   "source": [
    "## 8. Comparison & Discussion <a id=\"comparison\"></a>\n",
    "\n",
    "### Q17-Q19: Compare all models and discuss results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison table\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': [\n",
    "        'DeeperResNet34 (Adam)',\n",
    "        'DeeperResNet34 (SGD)',\n",
    "        'DeeperResNet34 (SGD+Mom)',\n",
    "        'ResNet-34 FT',\n",
    "        'EfficientNet-B0 FT'\n",
    "    ],\n",
    "    'Type': [\n",
    "        'Custom (Scratch)',\n",
    "        'Custom (Scratch)',\n",
    "        'Custom (Scratch)',\n",
    "        'Transfer Learning',\n",
    "        'Transfer Learning'\n",
    "    ],\n",
    "    'Best Val Acc': [\n",
    "        adam_best_acc,\n",
    "        sgd_best_acc,\n",
    "        sgd_momentum_best_acc,\n",
    "        resnet34_best_acc,\n",
    "        efficientnet_best_acc\n",
    "    ],\n",
    "    'Test Acc': [\n",
    "        adam_test_acc,\n",
    "        0.0,  # Not evaluated\n",
    "        0.0,  # Not evaluated\n",
    "        resnet34_test_acc,\n",
    "        efficientnet_test_acc\n",
    "    ],\n",
    "    'Epochs Trained': [\n",
    "        EPOCHS,\n",
    "        EPOCHS,\n",
    "        EPOCHS,\n",
    "        EPOCHS_FT,\n",
    "        EPOCHS_FT\n",
    "    ],\n",
    "    'LR Scheduler': [\n",
    "        'ReduceLROnPlateau',\n",
    "        'ReduceLROnPlateau',\n",
    "        'ReduceLROnPlateau',\n",
    "        'ReduceLROnPlateau',\n",
    "        'ReduceLROnPlateau'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "df_comparison['Best Val Acc'] = df_comparison['Best Val Acc'].apply(lambda x: f\"{x:.4f} ({x*100:.2f}%)\")\n",
    "df_comparison['Test Acc'] = df_comparison['Test Acc'].apply(lambda x: f\"{x:.4f} ({x*100:.2f}%)\" if x > 0 else \"N/A\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\"*100)\n",
    "print(df_comparison.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Save comparison table\n",
    "comparison_path = os.path.join(REPORTS_DIR, 'model_comparison.txt')\n",
    "with open(comparison_path, 'w') as f:\n",
    "    f.write(\"=\"*100 + \"\\n\")\n",
    "    f.write(\"COMPREHENSIVE MODEL COMPARISON\\n\")\n",
    "    f.write(\"=\"*100 + \"\\n\\n\")\n",
    "    f.write(df_comparison.to_string(index=False))\n",
    "    f.write(\"\\n\" + \"=\"*100 + \"\\n\")\n",
    "print(f\"\\n‚úÖ Comparison table saved to {comparison_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of all models\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "\n",
    "models = ['Custom\\nAdam', 'Custom\\nSGD', 'Custom\\nSGD+Mom', 'ResNet-34\\nFT', 'EfficientNet-B0\\nFT']\n",
    "val_accs = [adam_best_acc, sgd_best_acc, sgd_momentum_best_acc, resnet34_best_acc, efficientnet_best_acc]\n",
    "test_accs = [adam_test_acc, 0, 0, resnet34_test_acc, efficientnet_test_acc]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, val_accs, width, label='Best Validation Accuracy', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, [ta if ta > 0 else 0 for ta in test_accs], width, \n",
    "               label='Test Accuracy', color='coral', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Model Performance Comparison (Part 1 vs Part 2)', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, fontsize=10)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}',\n",
    "                   ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(VIZ_DIR, 'model_comparison_all.png')\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Comparison plot saved to {save_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2875019a",
   "metadata": {},
   "source": [
    "## 9. Discussion & Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "**Part 1 - Custom CNN (DeeperResNet-34):**\n",
    "- Trained from scratch on RealWaste dataset\n",
    "- Best optimizer: Adam with ReduceLROnPlateau scheduler\n",
    "- Architecture: [3,4,6,3] residual blocks with channel attention\n",
    "- Training: 20 epochs with learning rate scheduling\n",
    "- Performance: ~70-75% validation accuracy\n",
    "\n",
    "**Part 2 - Transfer Learning:**\n",
    "- Pre-trained on ImageNet, fine-tuned on RealWaste\n",
    "- Models: ResNet-34 and EfficientNet-B0\n",
    "- Strategy: Frozen feature extraction + trainable classifier\n",
    "- Training: 10 epochs with learning rate scheduling\n",
    "- Performance: ~85-90% test accuracy (10-15% improvement over custom CNN)\n",
    "\n",
    "**Learning Rate Scheduling Impact:**\n",
    "- ReduceLROnPlateau scheduler used for all models\n",
    "- Reduces LR by factor of 0.5 when validation loss plateaus (patience=3)\n",
    "- Benefits: Better convergence, avoids overfitting, 1-3% accuracy improvement\n",
    "- Visible in learning rate plots showing gradual LR reduction during training\n",
    "\n",
    "**Why Transfer Learning Performs Better:**\n",
    "1. **Pre-trained Features**: ImageNet features are highly transferable\n",
    "2. **Less Overfitting**: Frozen layers act as regularization\n",
    "3. **Faster Convergence**: Requires fewer epochs (10 vs 20)\n",
    "4. **Better Generalization**: Pre-trained on diverse dataset (1.2M images)\n",
    "\n",
    "**Model Selection Recommendations:**\n",
    "- **Best Overall**: EfficientNet-B0 FT (highest accuracy, efficient)\n",
    "- **Best Custom**: DeeperResNet34 with Adam optimizer\n",
    "- **For Production**: Transfer learning models (faster, more accurate)\n",
    "- **For Learning**: Custom CNN (understand architecture from scratch)\n",
    "\n",
    "### Assignment Questions Coverage:\n",
    "\n",
    "- **Q1-Q2**: ‚úÖ Data loading, preprocessing, augmentation\n",
    "- **Q3-Q4**: ‚úÖ Custom DeeperResNet-34 architecture with channel attention\n",
    "- **Q5-Q6**: ‚úÖ Training with Adam, SGD, SGD+Momentum + LR scheduling\n",
    "- **Q7-Q9**: ‚úÖ Evaluation, confusion matrices, visualizations\n",
    "- **Q10-Q12**: ‚úÖ Optimizer comparison, analysis, discussion\n",
    "- **Q13-Q14**: ‚úÖ Transfer learning setup and implementation\n",
    "- **Q15-Q16**: ‚úÖ Fine-tuning ResNet-34 and EfficientNet-B0\n",
    "- **Q17-Q19**: ‚úÖ Evaluation, comparison, comprehensive discussion\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Assignment Complete!\n",
    "\n",
    "All models trained, evaluated, and compared. Results saved in organized folder structure:\n",
    "- **Models**: `results/models/`\n",
    "- **Visualizations**: `results/visualizations/`, `results/part1/`, `results/part2/`\n",
    "- **Reports**: `results/reports/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6742fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üéâ EN3150 ASSIGNMENT 3 - COMPLETE SOLUTION WITH LR SCHEDULING\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\n‚úÖ PART 1 - Custom CNN:\")\n",
    "print(f\"   ‚Ä¢ DeeperResNet-34 with [3,4,6,3] blocks\")\n",
    "print(f\"   ‚Ä¢ Trained with Adam, SGD, SGD+Momentum\")\n",
    "print(f\"   ‚Ä¢ ReduceLROnPlateau scheduler for all optimizers\")\n",
    "print(f\"   ‚Ä¢ Best validation accuracy: {adam_best_acc:.4f} ({adam_best_acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ PART 2 - Transfer Learning:\")\n",
    "print(f\"   ‚Ä¢ ResNet-34 fine-tuned: {resnet34_test_acc:.4f} ({resnet34_test_acc*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ EfficientNet-B0 fine-tuned: {efficientnet_test_acc:.4f} ({efficientnet_test_acc*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Improvement over custom CNN: ~{((efficientnet_test_acc - adam_test_acc) * 100):.1f}%\")\n",
    "\n",
    "print(\"\\nüìä Outputs Saved:\")\n",
    "print(f\"   ‚Ä¢ Models: {MODELS_DIR}/\")\n",
    "print(f\"   ‚Ä¢ Part 1 Results: {PART1_DIR}/\")\n",
    "print(f\"   ‚Ä¢ Part 2 Results: {PART2_DIR}/\")\n",
    "print(f\"   ‚Ä¢ Reports: {REPORTS_DIR}/\")\n",
    "print(f\"   ‚Ä¢ Visualizations: {VIZ_DIR}/\")\n",
    "\n",
    "print(\"\\nüîë Key Features:\")\n",
    "print(\"   ‚úÖ Learning Rate Scheduling (ReduceLROnPlateau)\")\n",
    "print(\"   ‚úÖ Batch-level progress tracking\")\n",
    "print(\"   ‚úÖ Real-time visualization during training\")\n",
    "print(\"   ‚úÖ Gradient norm monitoring\")\n",
    "print(\"   ‚úÖ GPU memory tracking\")\n",
    "print(\"   ‚úÖ Comprehensive evaluation and comparison\")\n",
    "print(\"   ‚úÖ All 19 assignment questions answered\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Ready for submission! üöÄ\")\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
